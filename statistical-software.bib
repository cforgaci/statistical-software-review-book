
@misc{reside-ic_pull_nodate,
	title = {Pull {Request} review process - {Reside}-{IC}},
	url = {https://reside-ic.github.io/articles/pull-requests/},
	urldate = {2020-05-05},
	author = {Reside-IC}
}

@book{group_httptransparentstatisticsorg_transparent_2019,
	title = {Transparent {Statistics} {Guidelines}},
	url = {https://transparentstats.github.io/guidelines/index.html},
	abstract = {Guidelines, FAQ, and exemplar analyses},
	urldate = {2020-04-13},
	author = {Group (http://transparentstatistics.org/), Transparent Statistics in HCI Working},
	year = {2019}
}

@misc{nust_codecheck_nodate,
	title = {{CODECHECK} process},
	url = {https://codecheck.org.uk//process/},
	abstract = {CODECHECK is a process for independent reproduction of computations and awarding of time-stamped certificates for successful reproductions of scholarly articles.},
	language = {en},
	urldate = {2020-04-09},
	journal = {CODECHECK},
	author = {Nüst, Stephen Eglen \& Daniel}
}

@techreport{jackson_software_2011,
	title = {Software {Evaluation} {Guide}},
	url = {https://www.software.ac.uk/resources/guides-everything/software-evaluation-guide},
	urldate = {2020-04-09},
	institution = {Software Sustainability Institute},
	author = {Jackson, Mike and Crouch, Steve and Baxter, Rob},
	year = {2011}
}

@techreport{van_gompel_clariahsoftware-quality-guidelines_2016,
	title = {{CLARIAH}/software-quality-guidelines},
	url = {https://github.com/CLARIAH/software-quality-guidelines},
	abstract = {Guidelines for software quality \& sustainability (CLARIAH WP2 task 54.100)},
	urldate = {2020-04-09},
	institution = {CLARIAH},
	author = {van Gompel, Maarten and Noordzij, Jauco and de Valk, Reinier and Scharnhorst, Andrea},
	year = {2016},
	note = {original-date: 2016-05-27T16:53:29Z},
	keywords = {sustainability, quality-guidelines, software-quality}
}

@techreport{object_management_group_automated_2016,
	title = {Automated {Source} {Code} {CISQ} {Maintainability} {Measure} {Specification} {Version} 1.0},
	url = {https://www.omg.org/spec/ASCMM/},
	urldate = {2020-04-09},
	institution = {OMG (Object Management Group)},
	author = {Object Management Group},
	year = {2016}
}

@techreport{scott_esip_2016,
	title = {{ESIP} {Software} {Guidelines} {Draft}},
	url = {https://esipfed.github.io/Software-Assessment-Guidelines/guidelines.html},
	urldate = {2020-04-09},
	institution = {ESIP (Earth Science Information Partners)},
	author = {Scott, Soren},
	year = {2016}
}

@misc{center_dlr_nodate,
	title = {{DLR} {Software} {Initiative} {Guidelines}},
	url = {https://rse.dlr.de/01_guidelines.html},
	abstract = {The software enigineering initiative of the German Aerospace Center (DLR) - Supporting DLR scientits writing better software!},
	language = {en},
	urldate = {2020-04-09},
	journal = {DLR Software Engineering Initiative},
	author = {Center, German Aerospace}
}

@article{lamprecht_towards_2019,
	title = {Towards {FAIR} principles for\&nbsp;research\&nbsp;software},
	volume = {Preprint},
	issn = {2451-8484},
	url = {https://content.iospress.com/articles/data-science/ds190026},
	doi = {10.3233/DS-190026},
	abstract = {The FAIR Guiding Principles, published in 2016, aim to improve the findability, accessibility, interoperability and reusability of digital research objects for both humans and machines. Until now the FAIR principles have been mostly applied to resear},
	language = {en},
	number = {Preprint},
	urldate = {2020-04-09},
	journal = {Data Science},
	author = {Lamprecht, Anna-Lena and Garcia, Leyla and Kuzak, Mateusz and Martinez, Carlos and Arcila, Ricardo and Martin Del Pico, Eva and Dominguez Del Angel, Victoria and van de Sandt, Stephanie and Ison, Jon and Martinez, Paula Andrea and McQuilton, Peter and Valencia, Alfonso and Harrow, Jennifer and Psomopoulos, Fotis and Gelpi, Josep Ll and Chue Hong, Neil and Goble, Carole and Capella-Gutierrez, Salvador},
	month = jan,
	year = {2019},
	pages = {1--23}
}

@article{jimenez_four_2017,
	title = {Four simple recommendations to encourage best practices in research software},
	volume = {6},
	issn = {2046-1402},
	url = {https://f1000research.com/articles/6-876/v1},
	doi = {10.12688/f1000research.11407.1},
	abstract = {Scientific research relies on computer software, yet software is not always developed following practices that ensure its quality and sustainability. This manuscript does not aim to propose new software development best practices, but rather to provide simple recommendations that encourage the adoption of existing best practices. Software development best practices promote better quality software, and better quality software improves the reproducibility and reusability of research. These recommendations are designed around Open Source values, and provide practical suggestions that contribute to making research software and its source code more discoverable, reusable and transparent. This manuscript is aimed at developers, but also at organisations, projects, journals and funders that can increase the quality and sustainability of research software by encouraging the adoption of these recommendations.},
	language = {en},
	urldate = {2020-04-09},
	journal = {F1000Research},
	author = {Jiménez, Rafael C. and Kuzak, Mateusz and Alhamdoosh, Monther and Barker, Michelle and Batut, Bérénice and Borg, Mikael and Capella-Gutierrez, Salvador and Chue Hong, Neil and Cook, Martin and Corpas, Manuel and Flannery, Madison and Garcia, Leyla and Gelpí, Josep Ll. and Gladman, Simon and Goble, Carole and González Ferreiro, Montserrat and Gonzalez-Beltran, Alejandra and Griffin, Philippa C. and Grüning, Björn and Hagberg, Jonas and Holub, Petr and Hooft, Rob and Ison, Jon and Katz, Daniel S. and Leskošek, Brane and López Gómez, Federico and Oliveira, Luis J. and Mellor, David and Mosbergen, Rowland and Mulder, Nicola and Perez-Riverol, Yasset and Pergl, Robert and Pichler, Horst and Pope, Bernard and Sanz, Ferran and Schneider, Maria V. and Stodden, Victoria and Suchecki, Radosław and Svobodová Vařeková, Radka and Talvik, Harry-Anton and Todorov, Ilian and Treloar, Andrew and Tyagi, Sonika and van Gompel, Maarten and Vaughan, Daniel and Via, Allegra and Wang, Xiaochuan and Watson-Haigh, Nathan S. and Crouch, Steve},
	month = jun,
	year = {2017},
	pages = {876}
}

@misc{sheildsio_shieldsio_nodate,
	title = {Shields.io: {Quality} metadata badges for open source projects},
	url = {https://shields.io/},
	urldate = {2020-04-09},
	author = {sheilds.io}
}

@misc{van_rossum_pep_nodate,
	title = {{PEP} 8 -- {Style} {Guide} for {Python} {Code}},
	url = {https://www.python.org/dev/peps/pep-0008/},
	abstract = {The official home of the Python Programming Language},
	language = {en},
	urldate = {2020-04-09},
	journal = {Python.org},
	author = {van Rossum, Guido and Warsaw, Barry and Coghlan, Nick}
}

@misc{the_turing_way_community_turing_2019,
	title = {The {Turing} {Way}: {A} {Handbook} for {Reproducible} {Data} {Science}},
	shorttitle = {The {Turing} {Way}},
	url = {https://zenodo.org/record/3233986},
	abstract = {Reproducible research is necessary to ensure that scientific work can be trusted. Funders and publishers are beginning to require that publications include access to the underlying data and the analysis code. The goal is to ensure that all results can be independently verified and built upon in future work. This is sometimes easier said than done. Sharing these research outputs means understanding data management, library sciences, software development, and continuous integration techniques: skills that are not widely taught or expected of academic researchers and data scientists. The Turing Way is a handbook to support students, their supervisors, funders and journal editors in ensuring that reproducible data science is "too easy not to do". It will include training material on version control, analysis testing, and open and transparent communication with future users, and build on Turing Institute case studies and workshops. This project is openly developed and any and all questions, comments and recommendations are welcome at our github repository: https://github.com/alan-turing-institute/the-turing-way. Release log v0.0.4: Continuous integration chapter merged to master. v0.0.3: Reproducible environments chapter merged to master. v0.0.2: Version control chapter merged to master. v0.0.1: Reproducibility chapter merged to master.},
	urldate = {2020-04-09},
	publisher = {Zenodo},
	author = {The Turing Way Community and Becky Arnold and Louise Bowler and Sarah Gibson and Patricia Herterich and Rosie Higman and Anna Krystalli and Alexander Morley and Martin O'Reilly and Kirstie Whitaker},
	month = mar,
	year = {2019},
	doi = {10.5281/zenodo.3233986}
}

@incollection{batarseh_3_2020,
	title = {3 - {The} history and future prospects of open data and open source software},
	isbn = {978-0-12-818366-3},
	url = {http://www.sciencedirect.com/science/article/pii/B9780128183663000034},
	abstract = {Open data for all New Yorkers is the tagline on New York City's open data website. Open government is being promoted at most countries of the western world. Governments' transparency levels are being measured by the amount of data they share through their online public repositories. Additionally, open source software is promoted at governments, academia, and the industry—this is the new digital story of this century, and the new testament between the Gods of technology and there users; data and software openness will redefine the path forward and aim to rekindle our collective intelligence. Data and software openness can redefine Data Democracy and be the catalyst for its progress. This chapter provides a historical insight into data and software openness, the beginnings, the heroes, prospects for the future, and all things we cannot afford to negotiate or lose.},
	language = {en},
	urldate = {2020-04-03},
	booktitle = {Data {Democracy}},
	publisher = {Academic Press},
	author = {Batarseh, Feras A. and Kumar, Abhinav and Eisenberg, Sam},
	editor = {Batarseh, Feras A. and Yang, Ruixin},
	month = jan,
	year = {2020},
	doi = {10.1016/B978-0-12-818366-3.00003-4},
	keywords = {Open source software, Open data, Copyleft, Hacking},
	pages = {29--43}
}

@misc{wickham_r-libwaldo_2020,
	title = {r-lib/waldo},
	url = {https://github.com/r-lib/waldo},
	abstract = {Find differences between R objects.},
	urldate = {2020-03-30},
	publisher = {R infrastructure},
	author = {Wickham, Hadley},
	month = mar,
	year = {2020},
	note = {original-date: 2020-03-29T16:00:40Z},
	keywords = {diff, r, testing}
}

@misc{henry_lifecycle_2020,
	title = {lifecycle: {Manage} the {Life} {Cycle} of your {Package} {Functions}},
	copyright = {GPL-3},
	shorttitle = {lifecycle},
	url = {https://CRAN.R-project.org/package=lifecycle},
	abstract = {Manage the life cycle of your exported functions with shared conventions, documentation badges, and non-invasive deprecation warnings. The 'lifecycle' package defines four development stages (experimental, maturing, stable, and questioning) and three deprecation stages (soft-deprecated, deprecated, and defunct). It makes it easy to insert badges corresponding to these stages in your documentation. Usage of deprecated functions are signalled with increasing levels of non-invasive verbosity.},
	urldate = {2020-03-24},
	author = {Henry, Lionel and RStudio},
	month = mar,
	year = {2020}
}

@inproceedings{avelino_assessing_2017,
	address = {Cham},
	series = {{IFIP} {Advances} in {Information} and {Communication} {Technology}},
	title = {Assessing {Code} {Authorship}: {The} {Case} of the {Linux} {Kernel}},
	isbn = {978-3-319-57735-7},
	shorttitle = {Assessing {Code} {Authorship}},
	doi = {10.1007/978-3-319-57735-7_15},
	abstract = {Code authorship is a key information in large-scale open-source systems. Among others, it allows maintainers to assess division of work and identify key collaborators. Interestingly, open-source communities lack guidelines on how to manage authorship. This could be mitigated by setting to build an empirical body of knowledge on how authorship-related measures evolve in successful open-source communities. Towards that direction, we perform a case study on the Linux kernel. Our results show that: (a) only a small portion of developers (26\%) makes significant contributions to the code base; (b) the distribution of the number of files per author is highly skewed—a small group of top-authors (3\%) is responsible for hundreds of files, while most authors (75\%) are responsible for at most 11 files; (c) most authors (62\%) have a specialist profile; (d) authors with a high number of co-authorship connections tend to collaborate with others with less connections.},
	language = {en},
	booktitle = {Open {Source} {Systems}: {Towards} {Robust} {Practices}},
	publisher = {Springer International Publishing},
	author = {Avelino, Guilherme and Passos, Leonardo and Hora, Andre and Valente, Marco Tulio},
	editor = {Balaguer, Federico and Di Cosmo, Roberto and Garrido, Alejandra and Kon, Fabio and Robles, Gregorio and Zacchiroli, Stefano},
	year = {2017},
	keywords = {Code authorship, Developer networks, Linux kernel},
	pages = {151--163}
}

@misc{noauthor_overcoming_nodate,
	title = {Overcoming {Social} {Barriers} {When} {Contributing} to {Open} {Source} {Software} {Projects} {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/s10606-018-9335-z},
	urldate = {2020-03-18}
}

@misc{bossek_jakob_nodate,
	title = {Jakob {Bossek} - {PhD} candidate},
	url = {http://www.jakobbossek.de/software/},
	urldate = {2020-03-16},
	author = {Bossek, Jakob}
}

@misc{microsoft_microsoftnni_2020,
	title = {microsoft/nni},
	copyright = {MIT},
	url = {https://github.com/microsoft/nni},
	abstract = {An open source AutoML toolkit for automate machine learning lifecycle, including feature engineering, neural architecture search, model compression and hyper-parameter tuning.},
	urldate = {2020-03-16},
	publisher = {Microsoft},
	author = {{Microsoft}},
	month = mar,
	year = {2020},
	note = {original-date: 2018-06-01T05:51:44Z},
	keywords = {automated-feature-engineering, automated-machine-learning, automl, bayesian-optimization, data-science, deep-learning, deep-neural-network, distributed, feature-engineering, feature-extraction, hyperparameter-optimization, machine-learning, machine-learning-algorithms, model-compression, nas, neural-architecture-search, neural-network, python, pytorch, tensorflow}
}

@misc{uber_uberludwig_2020,
	title = {uber/ludwig},
	copyright = {Apache-2.0},
	url = {https://github.com/uber/ludwig},
	abstract = {Ludwig is a toolbox built on top of TensorFlow that allows to train and test deep learning models without the need to write code.},
	urldate = {2020-03-16},
	publisher = {Uber Open Source},
	author = {{uber}},
	month = mar,
	year = {2020},
	note = {original-date: 2018-12-27T23:58:12Z},
	keywords = {learning, machine, deep-learning, machine-learning, computer-vision, deep, deep-neural-networks, deeplearning, machinelearning, natural-language, natural-language-generation, natural-language-processing, natural-language-understanding, python3}
}

@misc{r_validation_hub_risk-based_nodate,
	title = {A {Risk}-based {Approach} for {Assessing} {R} package {Accuracy} within a {Validated} {Infrastructure}},
	url = {/white-paper//},
	language = {en-us},
	urldate = {2020-03-12},
	author = {{R Validation HUb}}
}

@book{wickham_tidyverse_2020,
	title = {The tidyverse style guide},
	url = {https://style.tidyverse.org/},
	abstract = {The tidyverse style guide},
	urldate = {2020-03-12},
	author = {Wickham, Hadley},
	year = {2020}
}

@misc{kuhn_conventions_2019,
	title = {Conventions for {R} {Modeling} {Packages}},
	url = {https://tidymodels.github.io/model-implementation-principles/},
	abstract = {Conventions for R Modeling Packages},
	urldate = {2020-03-12},
	author = {Kuhn, Max},
	year = {2019}
}

@misc{hayes_testing_nodate,
	title = {testing statistical software},
	url = {https://www.alexpghayes.com/blog/testing-statistical-software/},
	abstract = {Do you want some uncertainty with that?},
	language = {en-US},
	urldate = {2020-03-12},
	journal = {aleatoric},
	author = {Hayes, Alex}
}

@article{estivill-castro_why_2002,
	title = {Why so many clustering algorithms: a position paper},
	volume = {4},
	issn = {1931-0145},
	shorttitle = {Why so many clustering algorithms},
	url = {https://doi.org/10.1145/568574.568575},
	doi = {10.1145/568574.568575},
	abstract = {We argue that there are many clustering algorithms, because the notion of "cluster" cannot be precisely defined. Clustering is in the eye of the beholder, and as such, researchers have proposed many induction principles and models whose corresponding optimization problem can only be approximately solved by an even larger number of algorithms. Therefore, comparing clustering algorithms, must take into account a careful understanding of the inductive principles involved.},
	number = {1},
	urldate = {2020-03-11},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Estivill-Castro, Vladimir},
	month = jun,
	year = {2002},
	keywords = {clustering, clustering criterion, inductive principle},
	pages = {65--75}
}

@misc{maciver_most_nodate,
	title = {Most testing is ineffective - {Hypothesis}},
	url = {https://hypothesis.works/},
	urldate = {2020-03-05},
	author = {MacIver, David},
	keywords = {testing}
}

@misc{olsen_ludvigolsenxpectr_2020,
	title = {{LudvigOlsen}/xpectr},
	url = {https://github.com/LudvigOlsen/xpectr},
	abstract = {R package for generating expectations for `testthat` unit testing},
	urldate = {2020-03-02},
	author = {Olsen, Ludvig Renbo},
	month = mar,
	year = {2020},
	note = {original-date: 2020-01-15T14:35:53Z},
	keywords = {testing}
}

@misc{loo_markvanderlootinytest_2020,
	title = {markvanderloo/tinytest},
	copyright = {GPL-3.0},
	url = {https://github.com/markvanderloo/tinytest},
	abstract = {A lightweight, no-dependency, but full-featured package for unit testing in R},
	urldate = {2020-03-05},
	author = {Loo, Mark van der},
	month = mar,
	year = {2020},
	note = {original-date: 2019-02-01T16:22:04Z},
	keywords = {testing}
}

@misc{andersen_mikldkroxytest_2020,
	title = {mikldk/roxytest},
	url = {https://github.com/mikldk/roxytest},
	abstract = {Inline testthat tests with roxygen2. Contribute to mikldk/roxytest development by creating an account on GitHub.},
	urldate = {2020-03-05},
	author = {Andersen, Mikkel Meyer},
	month = mar,
	year = {2020},
	note = {original-date: 2019-07-24T10:19:29Z},
	keywords = {testing}
}

@misc{kiener_rwsearch_2020,
	title = {{RWsearch}: {Lazy} {Search} in {R} {Packages}, {Task} {Views}, {CRAN}, the {Web}. {All}-in-{One} {Download}},
	copyright = {GPL-2},
	shorttitle = {{RWsearch}},
	url = {https://CRAN.R-project.org/package=RWsearch},
	abstract = {Search by keywords in R packages, task views, CRAN, the web and display the results in console, txt, html or pdf pages. Download the whole documentation (html index, pdf manual, vignettes, source code, etc) with a single instruction. Visualize the package dependencies. Several functions for task view maintenance and exploration of CRAN archive. Quick links to more than 70 web search engines. Lazy evaluation of non-standard content is available throughout the package and eases the use of many functions.},
	urldate = {2020-02-26},
	author = {Kiener, Patrice},
	month = feb,
	year = {2020}
}

@misc{noauthor_go_nodate,
	title = {Go packages in {R} packages},
	url = {/blog/2017/06/09/go-packages-in-r-packages//},
	abstract = {purrple},
	language = {en},
	urldate = {2020-02-12}
}

@misc{core_infrastructure_coreinfrastructurebest-practices-badge_nodate,
	title = {coreinfrastructure/best-practices-badge},
	url = {https://github.com/coreinfrastructure/best-practices-badge},
	abstract = {🏆Core Infrastructure Initiative Best Practices Badge - coreinfrastructure/best-practices-badge},
	language = {en},
	urldate = {2020-02-11},
	journal = {GitHub},
	author = {Core Infrastructure}
}

@misc{noauthor_statistical_nodate,
	title = {Statistical {Modeling}, {Causal} {Inference}, and {Social} {Science}},
	url = {https://statmodeling.stat.columbia.edu/},
	urldate = {2020-02-11}
}

@article{belkin_reconciling_2019,
	title = {Reconciling modern machine learning practice and the bias-variance trade-off},
	url = {http://arxiv.org/abs/1812.11118},
	abstract = {Breakthroughs in machine learning are rapidly changing science and society, yet our fundamental understanding of this technology has lagged far behind. Indeed, one of the central tenets of the field, the bias-variance trade-off, appears to be at odds with the observed behavior of methods used in the modern machine learning practice. The bias-variance trade-off implies that a model should balance under-fitting and over-fitting: rich enough to express underlying structure in data, simple enough to avoid fitting spurious patterns. However, in the modern practice, very rich models such as neural networks are trained to exactly fit (i.e., interpolate) the data. Classically, such models would be considered over-fit, and yet they often obtain high accuracy on test data. This apparent contradiction has raised questions about the mathematical foundations of machine learning and their relevance to practitioners. In this paper, we reconcile the classical understanding and the modern practice within a unified performance curve. This "double descent" curve subsumes the textbook U-shaped bias-variance trade-off curve by showing how increasing model capacity beyond the point of interpolation results in improved performance. We provide evidence for the existence and ubiquity of double descent for a wide spectrum of models and datasets, and we posit a mechanism for its emergence. This connection between the performance and the structure of machine learning models delineates the limits of classical analyses, and has implications for both the theory and practice of machine learning.},
	urldate = {2020-02-11},
	journal = {arXiv:1812.11118 [cs, stat]},
	author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
	month = sep,
	year = {2019},
	note = {arXiv: 1812.11118},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@misc{noauthor_overfitting_nodate,
	title = {overfitting: a guided tour},
	shorttitle = {overfitting},
	url = {https://www.alexpghayes.com/blog/overfitting-a-guided-tour/},
	abstract = {Do you want some uncertainty with that?},
	language = {en-US},
	urldate = {2020-02-11},
	journal = {aleatoric}
}

@misc{noauthor_testing_nodate,
	title = {testing statistical software},
	url = {https://www.alexpghayes.com/blog/testing-statistical-software/},
	abstract = {Do you want some uncertainty with that?},
	language = {en-US},
	urldate = {2020-02-11},
	journal = {aleatoric}
}

@misc{noauthor_type_nodate,
	title = {type stable estimation},
	url = {https://www.alexpghayes.com/blog/type-stable-estimation/},
	abstract = {Do you want some uncertainty with that?},
	language = {en-US},
	urldate = {2020-02-11},
	journal = {aleatoric}
}

@misc{soetewey_antoine_stats_nodate,
	title = {Stats and {R}},
	url = {https://www.statsandr.com/},
	abstract = {A blog on statistics and R aiming at helping academics and professionals working with data to grasp important concepts in statistics and to apply them in R.},
	language = {en-US},
	urldate = {2020-02-11},
	journal = {Stats and R},
	author = {{Soetewey, Antoine}}
}

@misc{holdgraf_chris_predictably_nodate,
	title = {Predictably {Noisy}},
	url = {https://predictablynoisy.com/},
	language = {en},
	urldate = {2020-02-11},
	journal = {Predictably Noisy},
	author = {Holdgraf, Chris}
}

@misc{resnick_military_2019,
	title = {The military wants to build a bullshit detector for social science studies},
	url = {https://www.vox.com/science-and-health/2019/2/25/18211125/darpa-score-center-for-open-science-ai},
	abstract = {Artificial intelligence could potentially help psychology move past its "replication crisis."},
	language = {en},
	urldate = {2020-02-11},
	journal = {Vox},
	author = {Resnick, Brian},
	month = feb,
	year = {2019}
}

@techreport{yen_computational_2019,
	type = {preprint},
	title = {A {Computational} {Analysis} of the {Dynamics} of {R} {Style} {Based} on 94 {Million} {Lines} of {Code} from {All} {CRAN} {Packages} in the {Past} 20 {Years}},
	url = {https://osf.io/ts2wq},
	abstract = {There are so many programming style variations in R. We have analyzed 94 million lines of R code and quantified the evolution in popularity of 12 style-elements from 1998 to 2018. We attribute 3 main factors that drive changes in programming style: effect of style-guides, effect of introducing new features, and effect of editors. We have identified community-specific programming style variations. For example, there are programming communities which do not use snake\_case at all. A consensus in programming style is forming. We have summarised it into a \_Consensus-based Style\_.},
	urldate = {2020-01-24},
	institution = {SocArXiv},
	author = {Yen, Chai-Yi and Chang, Mia Huai-Wen and Chan, Chung-hong},
	month = jul,
	year = {2019},
	doi = {10.31235/osf.io/ts2wq}
}

@article{bzdok_statistics_2018,
	title = {Statistics versus machine learning},
	volume = {15},
	copyright = {2018 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	url = {https://www.nature.com/articles/nmeth.4642},
	doi = {10.1038/nmeth.4642},
	abstract = {Statistics draws population inferences from a sample, and machine learning finds generalizable predictive patterns.},
	language = {En},
	urldate = {2020-01-13},
	journal = {Nature Methods},
	author = {Bzdok, Danilo and Altman, Naomi and Krzywinski, Martin},
	month = apr,
	year = {2018},
	pages = {233--234}
}

@article{lenhardt_data_2014,
	title = {Data {Management} {Lifecycle} and {Software} {Lifecycle} {Management} in the {Context} of {Conducting} {Science}},
	volume = {2},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2049-9647},
	url = {http://openresearchsoftware.metajnl.com/articles/10.5334/jors.ax/},
	doi = {10.5334/jors.ax},
	abstract = {This paper examines the potential for comparisons of digital science data curation lifecycles to software lifecycle development to provide insight into promoting sustainable science software. The goal of this paper is to start a dialog examining the commonalities, connections, and potential complementarities between the data lifecycle and the software lifecycle in support of sustainable software. We argue, based on this initial survey, delving more deeply into the connections between data lifecycle approaches and software development lifecycles will enhance both in support of science.},
	language = {en},
	number = {1},
	urldate = {2020-01-08},
	journal = {Journal of Open Research Software},
	author = {Lenhardt, W. and Ahalt, Stanley and Blanton, Brian and Christopherson, Laura and Idaszak, Ray},
	month = jul,
	year = {2014},
	keywords = {data lifecycle, software development lifecycle, sustainable software},
	pages = {e15}
}

@article{mohammed_comparison_2010,
	title = {A {Comparison} {Between} {Five} {Models} {Of} {Software} {Engineering}},
	volume = {7},
	abstract = {This research deals with a vital and important issue in computer world. It is concerned with the software management processes that examine the area of software development through the development models, which are known as software development life cycle. It represents five of the development models namely, waterfall, Iteration, V-shaped, spiral and Extreme programming. These models have advantages and disadvantages as well. Therefore, the main objective of this research is to represent different models of software development and make a comparison between them to show the features and defects of each model.},
	number = {5},
	journal = {International Journal of Computer Science},
	author = {Mohammed, Nabil and Munassar, Ali and Govardhan, A.},
	year = {2010}
}

@article{kumar_critical_2016,
	title = {Critical {Analysis} of {Software} {Process} {Models}},
	volume = {NCACA 2016},
	url = {https://www.ijcaonline.org/proceedings/ncaca2016/number2/26176-1043},
	abstract = {IJCA is a computer science and electronics journal related with Theoretical Informatics, Quantum Computing, Software Testing, Computer Vision, Digital Systems, Pervasive Computing, Computational Topology etc.},
	language = {en-gb},
	number = {2},
	urldate = {2020-01-08},
	journal = {IJCA Proceedings on National Conference on Advances in Computing Applications},
	author = {Kumar, Subodh and Mishra, N. K. and Mehta, Sarkar Sharan},
	month = sep,
	year = {2016},
	pages = {12--14}
}

@article{boettiger_building_2015,
	title = {Building {Software}, {Building} {Community}: {Lessons} from the {rOpenSci} {Project}},
	volume = {3},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2049-9647},
	shorttitle = {Building {Software}, {Building} {Community}},
	url = {http://openresearchsoftware.metajnl.com/articles/10.5334/jors.bu/},
	doi = {10.5334/jors.bu},
	abstract = {rOpenSci is a developer collective originally formed in 2011 by graduate students and post-docs from ecology and evolutionary biology to collaborate on building software tools to facilitate a more open and synthetic approach in the face of transformative rise of large and heterogeneous data. Born on the internet (the collective only began through chance discussions over social media), we have grown into a widely recognized effort that supports an ecosystem of some 45 software packages, engages scores of collaborators, has taught dozens of workshops around the world, and has secured over \$480,000 in grant support. As young scientists working in an academic context largely without direct support for our efforts, we have first hand experience with most of the the technical and social challenges WSSSPE seeks to address. In this paper we provide an experience report which describes our approach and success in building an effective and diverse community.},
	language = {en},
	number = {1},
	urldate = {2020-01-08},
	journal = {Journal of Open Research Software},
	author = {Boettiger, Carl and Chamberlain, Scott and Hart, Edmund and Ram, Karthik},
	month = nov,
	year = {2015},
	keywords = {R, open science, data science, ropensci},
	pages = {e8}
}

@misc{noauthor_large_nodate,
	title = {A large scale study of programming languages and code quality in github {\textbar} {Proceedings} of the 22nd {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	url = {https://dl.acm.org/doi/abs/10.1145/2635868.2635922},
	language = {EN},
	urldate = {2020-01-08}
}

@article{spencer_open-source_2015,
	title = {Open-{Source} {Development} {Experiences} in {Scientific} {Software}: {The} {HANDE} {Quantum} {Monte} {Carlo} {Project}},
	volume = {3},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2049-9647},
	shorttitle = {Open-{Source} {Development} {Experiences} in {Scientific} {Software}},
	url = {http://openresearchsoftware.metajnl.com/articles/10.5334/jors.bw/},
	doi = {10.5334/jors.bw},
	abstract = {The HANDE quantum Monte Carlo project offers accessible stochastic algorithms for general use for scientists in the field of quantum chemistry. HANDE is an ambitious and general high-performance code developed by a geographically-dispersed team with a variety of backgrounds in computational science. In the course of preparing a public, open-source release, we have taken this opportunity to step back and look at what we have done and what we hope to do in the future. We pay particular attention to development processes, the approach taken to train students joining the project, and how a flat hierarchical structure aids communication.},
	language = {en},
	number = {1},
	urldate = {2020-01-08},
	journal = {Journal of Open Research Software},
	author = {Spencer, J. S. and Blunt, N. S. and Vigor, W. A. and Malone, Fionn D. and Foulkes, W. M. C. and Shepherd, James J. and Thom, A. J. W.},
	month = nov,
	year = {2015},
	keywords = {software development, student training},
	pages = {e9}
}

@article{downs_community_2015,
	title = {Community {Recommendations} for {Sustainable} {Scientific} {Software}},
	volume = {3},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2049-9647},
	url = {http://openresearchsoftware.metajnl.com/articles/10.5334/jors.bt/},
	doi = {10.5334/jors.bt},
	abstract = {Science software has contributed to research practices, but the sustainability of scientific software presents challenges for the future use of research resources. Identifying improvements for science software sustainability practices can contribute to the re-use of science software. A focus group study was conducted to identify ways to improve science software sustainability practices of the Earth science community. A facilitated, roundtable discussion activity at the 2014 Federation of Earth Science Information Partners (ESIP) Summer Meeting elicited recommendations on community activities to improve practices for the sustainability of scientific software. These suggestions fell into three broad themes – (1) improving collaboration and community engagement through publications and presentations (2) developing workshops, training, and documenting best practices and (3) creating incentives and motivation with awards, citation and a reviewed software repository. In addition to the recommendations coming out of the roundtable activity, this paper highlights how community-led groups such as ESIP are key to move a sustainable software effort in its various forms from concept to reality.},
	language = {en},
	number = {1},
	urldate = {2020-01-08},
	journal = {Journal of Open Research Software},
	author = {Downs, Robert R. and Lenhardt, W. Christopher and Robinson, Erin and Davis, Ethan and Weber, Nicholas},
	month = nov,
	year = {2015},
	keywords = {focus groups, Science software, software sustainability, sustainable systems},
	pages = {e11}
}

@book{myers_art_2012,
	address = {Hoboken, NJ},
	title = {The art of software testing},
	isbn = {978-1-118-03196-4},
	language = {English},
	publisher = {Wiley},
	author = {Myers, Glenford J and Badgett, Tom and Sandler, Corey},
	year = {2012},
	note = {OCLC: 775717314}
}

@misc{center_for_devices_and_radiological_health_general_2019,
	title = {General {Principles} of {Software} {Validation}},
	url = {http://www.fda.gov/regulatory-information/search-fda-guidance-documents/general-principles-software-validation},
	abstract = {General validation principles of medical device software or the validation of software used to design, develop, or manufacture medical devices.},
	language = {en},
	urldate = {2019-12-23},
	journal = {U.S. Food and Drug Administration},
	author = {{Center for Devices and Radiological Health}},
	month = may,
	year = {2019}
}

@techreport{the_r_foundation_for_statistical_computing_r:_2018,
	title = {R: {Regulatory} {Compliance} and {Validation} {IssuesA} {Guidance} {Document} for the {Use} of {R} in {Regulated} {ClinicalTrial} {Environments}},
	url = {https://www.r-project.org/doc/R-FDA.pdf},
	institution = {The R Foundation for Statistical Computing},
	author = {{The R Foundation for Statistical Computing}},
	year = {2018}
}

@book{ammann_introduction_2017,
	title = {Introduction to software testing},
	isbn = {978-1-107-17201-2},
	language = {English},
	publisher = {Cambridge University Press},
	author = {Ammann, Paul and Offutt, Jeff},
	year = {2017},
	note = {OCLC: 953738932}
}

@article{gebru_datasheets_2019,
	title = {Datasheets for {Datasets}},
	url = {http://arxiv.org/abs/1803.09010},
	abstract = {Currently there is no standard way to identify how a dataset was created, and what characteristics, motivations, and potential skews it represents. To begin to address this issue, we propose the concept of a datasheet for datasets, a short document to accompany public datasets, commercial APIs, and pretrained models. The goal of this proposal is to enable better communication between dataset creators and users, and help the AI community move toward greater transparency and accountability. By analogy, in computer hardware, it has become industry standard to accompany everything from the simplest components (e.g., resistors), to the most complex microprocessor chips, with datasheets detailing standard operating characteristics, test results, recommended usage, and other information. We outline some of the questions a datasheet for datasets should answer. These questions focus on when, where, and how the training data was gathered, its recommended use cases, and, in the case of human-centric datasets, information regarding the subjects' demographics and consent as applicable. We develop prototypes of datasheets for two well-known datasets: Labeled Faces in The Wild and the Pang {\textbackslash}\& Lee Polarity Dataset.},
	urldate = {2019-12-20},
	journal = {arXiv:1803.09010 [cs]},
	author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daumeé III, Hal and Crawford, Kate},
	month = apr,
	year = {2019},
	note = {arXiv: 1803.09010},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Databases}
}

@misc{health_guidance_2018,
	title = {Guidance for the {Use} of {Bayesian} {Statistics} in {Medical} {Device} {Clinical} {Trials} ({PDF} {Version})},
	url = {http://www.fda.gov/regulatory-information/search-fda-guidance-documents/guidance-use-bayesian-statistics-medical-device-clinical-trials-pdf-version},
	language = {en},
	urldate = {2019-12-18},
	journal = {U.S. Food and Drug Administration},
	author = {Health, Center for Devices {and} Radiological},
	month = jan,
	year = {2018}
}

@misc{research_e9_2019,
	title = {E9 {Statistical} {Principles} for {Clinical} {Trials}},
	url = {http://www.fda.gov/regulatory-information/search-fda-guidance-documents/e9-statistical-principles-clinical-trials},
	abstract = {International Council on Harmonisation - Efficacy},
	language = {en},
	urldate = {2019-12-18},
	journal = {U.S. Food and Drug Administration},
	author = {Research, Center for Drug Evaluation and},
	month = may,
	year = {2019}
}

@inproceedings{german_evolution_2013,
	title = {The {Evolution} of the {R} {Software} {Ecosystem}},
	doi = {10.1109/CSMR.2013.33},
	abstract = {Software ecosystems form the heart of modern companies' collaboration strategies with end users, open source developers and other companies. An ecosystem consists of a core platform and a halo of user contributions that provide value to a company or project. In order to sustain the level and number of high-quality contributions, it is crucial for companies and contributors to understand how ecosystems tend to evolve and can be maintained successfully over time. As a first step, this paper explores the evolution characteristics of the statistical computing project GNU R, which is a successful, end-user programming ecosystem. We find that the ecosystem of user-contributed R packages has been growing steadily since R's conception, at a significantly faster rate than core packages, yet each individual package remains stable in size. We also identified differences in the way user-contributed and core packages are able to attract an active community of users.},
	booktitle = {2013 17th {European} {Conference} on {Software} {Maintenance} and {Reengineering}},
	author = {German, Daniel M. and Adams, Bram and Hassan, Ahmed E.},
	month = mar,
	year = {2013},
	note = {ISSN: 1534-5351},
	keywords = {R, Software, Programming, Communities, Companies, Documentation, Ecosystems, Electronic mail, Evolution, GNU R statistical computing project, R software ecosystem, Software ecosystems, software engineering, software evolution, software packages, user community, user contribution, user interfaces, user-contributed R package},
	pages = {243--252}
}

@misc{bewerunge_peter_validation_2010,
	title = {Validation of {Open}-{Source}-{Software} {Usingthe} example of {R}},
	url = {https://www.lexjansen.com/phuse/2010/rg/RG03.pdf},
	urldate = {2019-12-17},
	author = {Bewerunge, Peter},
	year = {2010}
}

@incollection{stokes_21_2012,
	series = {Woodhead {Publishing} {Series} in {Biomedicine}},
	title = {21 - {Validation} and regulatory compliance of free/open source software},
	isbn = {978-1-907568-97-8},
	url = {http://www.sciencedirect.com/science/article/pii/B9781907568978500217},
	abstract = {Open source systems offer a number of advantages, but the need to formally validate some open source applications can be a challenge where there is no clearly defined ‘software vendor’. In these cases the regulated company must assume responsibility for controlling a validated open source application that is subject to ongoing change in the wider software development community. Key to this is knowing which open source applications require validation, identifying the additional risks posed by the use of open source software and understanding how standard risk-based validation models need to be adapted for use with software that is subject to ongoing refinement.},
	language = {en},
	urldate = {2019-12-17},
	booktitle = {Open {Source} {Software} in {Life} {Science} {Research}},
	publisher = {Woodhead Publishing},
	author = {Stokes, David},
	editor = {Harland, Lee and Forster, Mark},
	month = jan,
	year = {2012},
	doi = {10.1533/9781908818249.481},
	keywords = {compliance, risk, GAMP®, validation, verification},
	pages = {481--504}
}

@book{mili_software_2015,
	title = {Software testing: concepts and operations},
	isbn = {978-1-118-66287-8},
	shorttitle = {Software testing},
	language = {English},
	publisher = {Wiley},
	author = {Mili, Ali},
	year = {2015},
	note = {OCLC: 875249253}
}

@book{alpaev_software_2017,
	title = {Software testing automation tips: 50 things automation engineers should know},
	isbn = {978-1-4842-3162-3 978-1-4842-3161-6},
	shorttitle = {Software testing automation tips},
	url = {http://www.books24x7.com/marc.asp?bookid=135445},
	abstract = {Quickly access 50 tips for software test engineers using automated methods. The tips point to practices that save time and increase the accuracy and reliability of automated test techniques. Techniques that play well during demos of testing tools often are not the optimal techniques to apply on a running project. This book highlights those differences, helping you apply techniques that are repeatable and callable in professionally run software development projects. Emphasis is placed on creating tests that, while automated, are easily adapted as the software under construction evolves toward its final form. Techniques in the book are arranged into five categories: scripting, testing, the environment, running and logging of tests, and reviewing of the results. Every automation engineer sooner or later will face similar issues to the ones covered in these categories, and you will benefit from the simple and clear answers provided in this book. While the focus of the book is on the use of automated tools, the tips are not specific to any one vendor solution. The tips cover general issues that are faced no matter the specific tool, and are broadly applicable, often even to manual testing efforts. What You'll Learn: Employ best-practices in automated test design Write test scripts that will easily be understood by others Choose the proper environment for running automated tests Avoid techniques that demo well, but do not scale in practice Manage tests effectively, including testing of test scripts themselves Know when to go beyond automation to employ manual methods instead.},
	language = {English},
	urldate = {2019-12-05},
	author = {Alpaev, Gennadiy},
	year = {2017},
	note = {OCLC: 1008962892}
}

@book{mohanty_trends_2017,
	title = {Trends in {Software} {Testing}},
	isbn = {978-981-10-1415-4 978-981-10-1414-7},
	url = {http://www.UTS.eblib.com.AU/EBLWeb/patron/?target=patron&extendedid=P_4613345_0},
	abstract = {This book is focused on the advancements in the field of software testing and the innovative practices that the industry is adopting. Considering the widely varied nature of software testing, the book addresses contemporary aspects that are important for both academia and industry. There are dedicated chapters on seamless high-efficiency frameworks, automation on regression testing, software by search, and system evolution management. There are a host of mathematical models that are promising for software quality improvement by model-based testing. There are three chapters addressing this concern. Students and researchers in particular will find these chapters useful for their mathematical strength and rigor. Other topics covered include uncertainty in testing, software security testing, testing as a service, test technical debt (or test debt), disruption caused by digital advancement (social media, cloud computing, mobile application and data analytics), and challenges and benefits of outsourcing. The book will be of interest to students, researchers as well as professionals in the software industry.},
	language = {English},
	urldate = {2019-12-05},
	author = {Mohanty, Hrushikesha and Mohanty, J. R and Balakrishnan, Arunkumar},
	year = {2017},
	note = {OCLC: 957634733}
}

@book{black_foundations_2012,
	address = {Andover},
	title = {Foundations of software testing {ISTQB} certification},
	isbn = {978-1-4080-4405-6},
	language = {English},
	publisher = {Cengage Learning},
	author = {Black, Rex and Veenendaal, Erik van and Graham, Dorothy},
	year = {2012},
	note = {OCLC: 934737405}
}

@book{chockler_validation_2015,
	title = {Validation of {Evolving} {Software}},
	isbn = {978-3-319-10622-9},
	url = {https://www.springer.com/gp/book/9783319106229},
	abstract = {This book describes the methodology and accompanying technology for reducing the costs of validation of changes by introducing automatic techniques to analyze and test software increments. It builds a unified approach to efficient and reliable validation of changes and upgrades, and may be used as a research monograph and a reference book.},
	language = {en},
	urldate = {2019-12-05},
	publisher = {Springer International Publishing},
	editor = {Chockler, Hana and Kroening, Daniel and Mariani, Leonardo and Sharygina, Natasha},
	year = {2015},
	doi = {10.1007/978-3-319-10623-6}
}

@book{vogel_medical_2011,
	address = {Boston},
	title = {Medical device software verification, validation and compliance},
	isbn = {978-1-59693-423-8 978-1-5231-1739-0},
	url = {http://site.ebrary.com/id/10436227},
	abstract = {Here's the first book written specifically to help medical device and software engineers, QA and compliance professionals, and corporate business managers better understand and implement critical verification and validation processes for medical device software. Offering you a much broader, higher-level picture than other books in this field, this book helps you think critically about software validation -- to build confidence in your software's safety and effectiveness. The book presents validation activities for each phase of the development lifecycle and shows: why these activities are important and add value; how to undertake them; and what outputs need to be created to document the validation process. From software embedded within medical devices, to software that performs as a medical device itself, this comprehensive book explains how properly handled validation throughout the development lifecycle can help bring medical devices to completion sooner, at higher quality, and in compliance with regulations. Additionally, an entire part of the book is devoted to the validation of software that automates any part of a manufacturer's quality system and is regulated by 21 CFR 820.70(i). DVD Included! Contains a collection of FDA regulations and guidance documents related to software in the medical device industry, valuable sample forms and templates, and supplemental figures that support key topics covered in the book.},
	language = {English},
	urldate = {2019-12-05},
	publisher = {Artech House},
	author = {Vogel, David A},
	year = {2011},
	note = {OCLC: 694732909}
}

@book{fisher_software_2007,
	title = {Software {Verification} and {Validation}: {An} {Engineering} and {Scientific} {Approach}},
	isbn = {978-0-387-32725-9},
	shorttitle = {Software {Verification} and {Validation}},
	url = {https://www.springer.com/gp/book/9780387327259},
	abstract = {The World is lacking an in-depth technical book describing the methods and techniques used to provide confidence in our system software. Not only is the U.S. government more focused on software safety in today's market, but private industry and academia are as well. The methods and techniques that provide such confidence are commonly called software verification and validation. Software Verification and Validation: An Engineering and Scientific Approach, a professional book, fills the critical need for an in-depth technical reference providing the methods and techniques for building and maintaining confidence in many varieties of system software. The intent of this volume is to help develop reliable answers to such critical questions as: 1) Are we building the right software for the need? 2) Are we building the software right? Software Verification and Validation: An Engineering and Scientific Approach is structured for research scientists and practitioners in industry. This book is also suitable as a secondary textbook for advanced-level students in computer science and engineering.},
	language = {en},
	urldate = {2019-12-05},
	publisher = {Springer US},
	author = {Fisher, Marcus S.},
	year = {2007},
	doi = {10.1007/978-0-387-47939-2}
}

@book{haug_software_2001,
	address = {Berlin, Heidelberg},
	title = {Software {Quality} {Approaches}: {Testing}, {Verification}, and {Validation}: {Software} {Best} {Practice} 1},
	isbn = {978-3-642-56612-7},
	shorttitle = {Software {Quality} {Approaches}},
	url = {https://doi.org/10.1007/978-3-642-56612-7},
	abstract = {This book is a result of the European Experience Exchange (EUREX) project sponsored by the European Systems and Software Initiative for Software Best Practice in Europe. The EUREX project analyzed the industrial and economic impact and the common aspects and differences between and among more than 300 Software Process Improvement Experiments sponsored by the EU. The current volume offers a variety of perspectives on software quality issues resulting from that analysis, including testing, verification and validation. This area represents one of the "great unknowns" in software development in the sense that many organisations, especially small and medium-sized enterprises, have no purposeful process addressing these issues. As a result, this book is particularly meaningful for software practitioners in such enterprises, including both developers and line managers.},
	language = {English},
	urldate = {2019-12-05},
	publisher = {Springer Berlin Heidelberg},
	author = {Haug, Michael and Olsen, Eric W and Consolini, Luisa},
	year = {2001},
	note = {OCLC: 851829349}
}

@article{fagan_design_1976,
	title = {Design and code inspections to reduce errors in program development},
	volume = {15},
	issn = {0018-8670},
	url = {http://extras.springer.com/2002/978-3-642-59413-7/4/rom/pdf/Fagan_hist.pdf},
	doi = {10.1147/sj.153.0182},
	abstract = {We can summarize the discussion of design and code inspections and process control in developing programs as follows: 1. Describe the program development process in terms of operations, and define exit criteria which must be satisfied for completion of each operation. 2. Separate the objectives of the inspection process operations to keep the inspection team focused on one objective at a time: Operation Overview Preparation Inspection Rework Follow-up Objective Communications/education Education Find errors Fix errors Ensure all fixes are applied correctly 3. Classify errors by type, and rank frequency of occurrence of types. Identify which types to spend most time looking for in the inspection. 4. Describe how to look for presence of error types. 5. Analyze inspection results and use for constant process improvement (until process averages are reached and then use for process control).},
	number = {3},
	journal = {IBM Systems Journal},
	author = {Fagan, M. E.},
	year = {1976},
	pages = {182--211}
}

@inproceedings{sculley_machine_2014,
	title = {Machine {Learning}: {The} {High} {Interest} {Credit} {Card} of {Technical} {Debt}},
	shorttitle = {Machine {Learning}},
	booktitle = {{SE4ML}: {Software} {Engineering} for {Machine} {Learning} ({NIPS} 2014 {Workshop})},
	author = {Sculley, D. and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael},
	year = {2014}
}

@misc{noauthor_dslpdslp_2020,
	title = {dslp/dslp},
	copyright = {MIT},
	url = {https://github.com/dslp/dslp},
	abstract = {The Data Science Lifecycle Process is a process for taking data science teams from Idea to Value repeatedly and sustainably. The process is documented in this repo.},
	urldate = {2020-05-20},
	publisher = {dslp},
	month = may,
	year = {2020},
	note = {original-date: 2020-04-24T14:52:07Z}
}

@misc{gu_jokergoopkgndep_2020,
	title = {jokergoo/pkgndep},
	url = {https://github.com/jokergoo/pkgndep},
	abstract = {Check the Heaviness of Package Dependencies. Contribute to jokergoo/pkgndep development by creating an account on GitHub.},
	urldate = {2020-05-22},
	author = {Gu, Zuguang},
	month = may,
	year = {2020},
	note = {original-date: 2019-01-18T11:11:21Z}
}

@article{hasselbring_open_2020,
	title = {Open {Source} {Research} {Software}},
	volume = {53},
	issn = {0018-9162},
	url = {https://doi.org/10.1109/MC.2020.2998235},
	doi = {10.1109/MC.2020.2998235},
	abstract = {Reports on the need to make make software open source. It should be both archived for reproducibility and actively maintained for reusability. In computational and computer science, research software is a central asset for development activities. For good scientific practice, the resulting research software should be open source. Established open source software licenses provide sufficient options for granting permissions such that it should be the rare exception to keep research software closed. Proper engineering is required for obtaining reusable and sustainable research software. This way, software engineering methods may improve research in other disciplines. However, research in software engineering and computer science itself will also benefit when programs are reused. To study the state of the art in this field, we analyzed research software publishing practices in computer and computational science and observed significant differences: computational science emphasizes reproducibility, while computer science emphasizes reuse.},
	number = {8},
	urldate = {2020-11-26},
	journal = {Computer},
	author = {Hasselbring, Wilhelm and Carr, Leslie and Hettrick, Simon and Packer, Heather and Tiropanis, Thanassis},
	month = aug,
	year = {2020},
	note = {Num Pages: 5
Number: 8},
	pages = {84--88}
}

@article{wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
	volume = {3},
	copyright = {2016 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata201618},
	doi = {10.1038/sdata.2016.18},
	abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
	language = {en},
	number = {1},
	urldate = {2020-11-26},
	journal = {Scientific Data},
	author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	month = mar,
	year = {2016},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {160018}
}

@article{hasselbring_fair_2020,
	title = {From {FAIR} research data toward {FAIR} and open research software},
	volume = {62},
	issn = {1611-2776, 2196-7032},
	url = {https://www.degruyter.com/view/journals/itit/62/1/article-p39.xml},
	doi = {10.1515/itit-2019-0040},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d51e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}The Open Science agenda holds that science advances faster when we can build on existing results. Therefore, research data must be FAIR (Findable, Accessible, Interoperable, and Reusable) in order to advance the findability, reproducibility and reuse of research results. Besides the research data, all the processing steps on these data – as basis of scientific publications – have to be available, too.{\textless}/p{\textgreater}{\textless}p{\textgreater}For good scientific practice, the resulting research software should be both open and adhere to the FAIR principles to allow full repeatability, reproducibility, and reuse. As compared to research data, research software should be both archived for reproducibility and actively maintained for reusability.{\textless}/p{\textgreater}{\textless}p{\textgreater}The FAIR data principles do not require openness, but research software should be open source software. Established open source software licenses provide sufficient licensing options, such that it should be the rare exception to keep research software closed.{\textless}/p{\textgreater}{\textless}p{\textgreater}We review and analyze the current state in this area in order to give recommendations for making research software FAIR and open.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en},
	number = {1},
	urldate = {2020-11-26},
	journal = {it - Information Technology},
	author = {Hasselbring, Wilhelm and Carr, Leslie and Hettrick, Simon and Packer, Heather and Tiropanis, Thanassis},
	month = feb,
	year = {2020},
	note = {Publisher: De Gruyter Oldenbourg
Section: it - Information Technology},
	pages = {39--47}
}

@article{zirkelbach_modularization_2019,
	title = {Modularization of {Research} {Software} for {Collaborative} {Open} {Source} {Development}},
	url = {http://arxiv.org/abs/1907.05663},
	abstract = {Software systems evolve over their lifetime. Changing conditions, such as requirements or customer requests make it inevitable for developers to perform adjustments to the underlying code base. Especially in the context of open source software where everybody can contribute, requirements can change over time and new user groups may be addressed. In particular, research software is often not structured with a maintainable and extensible architecture. In combination with obsolescent technologies, this is a challenging task for new developers, especially, when students are involved. In this paper, we report on the modularization process and architecture of our open source research project ExplorViz towards a microservice architecture. The new architecture facilitates a collaborative development process for both researchers and students. We describe the modularization measures and present how we solved occurring issues and enhanced our development process. Afterwards, we illustrate our modularization approach with our modernized, extensible software system architecture and highlight the improved collaborative development process. Finally, we present a proof-of-concept implementation featuring several developed extensions in terms of architecture and extensibility.},
	urldate = {2020-11-26},
	journal = {arXiv:1907.05663 [cs]},
	author = {Zirkelbach, Christian and Krause, Alexander and Hasselbring, Wilhelm},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.05663},
	keywords = {Computer Science - Software Engineering}
}

@article{simon_value_2005,
	title = {The value of open standards and open-source software in government environments},
	volume = {44},
	issn = {0018-8670},
	doi = {10.1147/sj.442.0227},
	abstract = {Among the most noteworthy topics surrounding the recent widespread adoption of open-source software (OSS) are the convergence by governments worldwide to open standards and the ways in which open source embraces this convergence. There are continuing debates over the future of software and, in particular, the competition between OSS and proprietary software. Many studies by governments and by information technology analysts suggest that OSS and open standards are intimately connected and that the inherent value of open-source adoption may be attributable in large part to the embodiment of open standards in OSS. The government environment is changing rapidly in areas as diverse as homeland security and social services. Given the equally rapid changes in the information technology marketplace, the successful adoption of these new technologies by governments will depend on how well the strengths of proprietary software and OSS are understood and applied—especially with respect to the use of open standards to speed deployments of integrated capabilities that respond to emerging challenges. This paper evaluates the relative strengths of proprietary software and OSS as development techniques that embrace the open standards valued by governments.},
	number = {2},
	journal = {IBM Systems Journal},
	author = {Simon, K. D.},
	year = {2005},
	note = {Conference Name: IBM Systems Journal},
	pages = {227--238}
}

@article{corrado_importance_2005,
	title = {The {Importance} of {Open} {Access}, {Open} {Source}, and {Open} {Standards} for {Libraries}},
	url = {http://www.istl.org/05-spring/article2.html},
	doi = {10.5062/F42F7KD8},
	urldate = {2020-11-26},
	author = {Corrado, Edward M.},
	year = {2005},
	note = {Publisher: Issues in Science and Technology Librarianship}
}

@article{reynolds_open_2011,
	title = {Open {Source}, {Open} {Standards}, and {Health} {Care} {Information} {Systems}},
	volume = {13},
	url = {https://www.jmir.org/2011/1/e24/},
	doi = {10.2196/jmir.1521},
	abstract = {Recognition of the improvements in patient safety, quality of patient care, and efficiency that health care information systems have the potential to bring has led to significant investment. Globally the sale of health care information systems now represents a multibillion dollar industry. As policy makers, health care professionals, and patients, we have a responsibility to maximize the return on this investment. To this end we analyze alternative licensing and software development models, as well as the role of standards. We describe how licensing affects development. We argue for the superiority of open source licensing to promote safer, more effective health care information systems. We claim that open source licensing in health care information systems is essential to rational procurement strategy. [J Med Internet Res 2011;13(1):e24]},
	language = {en},
	number = {1},
	urldate = {2020-11-26},
	journal = {Journal of Medical Internet Research},
	author = {Reynolds, Carl J. and Wyatt, Jeremy C.},
	year = {2011},
	note = {Company: Journal of Medical Internet Research
Distributor: Journal of Medical Internet Research
Institution: Journal of Medical Internet Research
Label: Journal of Medical Internet Research
Publisher: JMIR Publications Inc., Toronto, Canada},
	pages = {e24}
}

@article{henkel_emergence_2014,
	series = {Open {Innovation}: {New} {Insights} and {Evidence}},
	title = {The emergence of openness: {How} and why firms adopt selective revealing in open innovation},
	volume = {43},
	issn = {0048-7333},
	shorttitle = {The emergence of openness},
	url = {http://www.sciencedirect.com/science/article/pii/S0048733313001595},
	doi = {10.1016/j.respol.2013.08.014},
	abstract = {Open innovation is often facilitated by strong intellectual property rights (IPRs), but it may also function, and even be boosted, when firms deliberately waive some of their IPRs. Extant literature has pointed out the potential benefits of such behavior, but falls short of explaining what triggers firms to practice it in the first place and to maintain or extend it. Since the waiving of IPRs runs counter to common views on strategy and competition and to engrained practices, this is a non-trivial question. To address it, we conduct an empirical study in a segment of the computer component industry which traditionally has taken a rather proprietary stance. With the advent of the open source operating system Linux, firms increasingly waived their IPRs on software drivers. We trace and analyze this process using both qualitative and quantitative methods. Our results indicate that component makers went through a learning process, which led some to realize how selectively waiving IPRs may be beneficial for their business. We uncover customer demand pull as the initial trigger and observe how a positive feedback loop sets in subsequently, leading to a further increase in the use of selective revealing. Overall, we find that openness develops into a new dimension of competition. We discuss the implication of our findings for research on open innovation and highlight how they impact managers in practice.},
	language = {en},
	number = {5},
	urldate = {2020-11-26},
	journal = {Research Policy},
	author = {Henkel, Joachim and Schöberl, Simone and Alexy, Oliver},
	month = jun,
	year = {2014},
	keywords = {Open source software, Embedded Linux, Multimethod study, Open innovation, Selective revealing},
	pages = {879--890}
}

@inproceedings{dedrick_why_2003,
	title = {Why firms adopt open source platforms: {A} grounded theory of innovation and standards adoption},
	volume = {145},
	shorttitle = {Why firms adopt open source platforms},
	url = {https://www.semanticscholar.org/paper/WHY-FIRMS-ADOPT-OPEN-SOURCE-PLATFORMS%3A-A-GROUNDED-Dedrick/13b7ab26e1476d8fee58d7065c920877e2bf8639},
	abstract = {There is a rich stream of research that studies technology adoption by individuals and organizations (Rogers, 1962; Tornatzky and Fleischer, 1990; Cooper \&amp; Zmud, 1990). This research considers factors such as the nature of the technology, the organizational and environmental context in which adoption decisions are made, and the processes by which users adopt and implement new technologies. Research on open source software has focused mainly on the motivations of open source programmers and the organization of open source projects (Kogut \&amp; Metiu, 2001; Lerner and Tirole, 2002; Benkler, 2002). Some researchers portray open source as an extension of the earlier open systems movement (West and Dedrick, 2001). While there has been some research on opensystems software adoption by corporate MIS organizations (Chau and Tam, 1997), the issue of open source adoption has received little attention. We use a series of interviews with MIS managers to develop a grounded theory of open source platform adoption. We then place our findings within the contexts of diffusion of innovation and economics of standards theories.},
	language = {en},
	urldate = {2020-11-26},
	booktitle = {Standard {Making}: {A} {Critical} {Research} {Frontier} for {Information} {Systems}},
	publisher = {MSIQ},
	author = {Dedrick, J.},
	year = {2003},
	pages = {236--257}
}

@article{cerri_open_2007,
	title = {Open standards, open formats, and open source},
	volume = {80},
	issn = {0164-1212},
	url = {http://www.sciencedirect.com/science/article/pii/S0164121207000581},
	doi = {10.1016/j.jss.2007.01.048},
	abstract = {The paper proposes some comments and reflections on the notion of “openness” and on how it relates to three important topics: open standards, open formats, and open source. Often, these terms are considered equivalent and/or mutually implicated: “open source is the only way to enforce and exploit open standards”. This position is misleading, as it increases the confusion about this complex and extremely critical topic. The paper clarifies the basic terms and concepts. This is instrumental to suggest a number of actions and practices aiming at promoting and defending openness in modern ICT products and services.},
	language = {en},
	number = {11},
	urldate = {2020-11-26},
	journal = {Journal of Systems and Software},
	author = {Cerri, Davide and Fuggetta, Alfonso},
	month = nov,
	year = {2007},
	keywords = {Open source, Interoperability, Open format, Open standard, Software development process, Software procurement},
	pages = {1930--1937}
}

@article{van_de_sandt_practice_2019,
	title = {Practice meets {Principle}: {Tracking} {Software} and {Data} {Citations} to {Zenodo} {DOIs}},
	shorttitle = {Practice meets {Principle}},
	url = {http://arxiv.org/abs/1911.00295},
	abstract = {Data and software citations are crucial for the transparency of research results and for the transmission of credit. But they are hard to track, because of the absence of a common citation standard. As a consequence, the FORCE11 recently proposed data and software citation principles as guidance for authors. Zenodo is recognized for the implementation of DOIs for software on a large scale. The minting of complementary DOIs for the version and concept allows measuring the impact of dynamic software. This article investigates characteristics of 5,456 citations to Zenodo data and software that were captured by the Asclepias Broker in January 2019. We analyzed the current state of data and software citation practices and the quality of software citation recommendations with regard to the impact of recent standardization efforts. Our findings prove that current citation practices and recommendations do not match proposed citation standards. We consequently suggest practical first steps towards the implementation of the software citation principles.},
	urldate = {2021-01-16},
	journal = {arXiv:1911.00295 [cs]},
	author = {van de Sandt, Stephanie and Nielsen, Lars Holm and Ioannidis, Alexandros and Muench, August and Henneken, Edwin and Accomazzi, Alberto and Bigarella, Chiara and Lopez, Jose Benito Gonzalez and Dallmeier-Tiessen, Sünje},
	month = nov,
	year = {2019},
	note = {arXiv: 1911.00295},
	keywords = {Computer Science - Digital Libraries}
}

@book{muenchow_chapter_nodate,
	title = {Chapter 11 {Statistical} learning {\textbar} {Geocomputation} with {R}},
	url = {https://geocompr.robinlovelace.net/},
	abstract = {Chapter 11 Statistical learning {\textbar} Geocomputation with R is for people who want to analyze, visualize and model geographic data with open source software. It is based on R, a statistical programming language that has powerful data processing, visualization, and geospatial capabilities. The book equips you with the knowledge and skills to tackle a wide range of issues manifested in geographic data, including those with scientific, societal, and environmental implications. This book will interest people from many backgrounds, especially Geographic Information Systems (GIS) users interested in applying their domain-specific knowledge in a powerful open source language for data science, and R users interested in extending their skills to handle spatial data.},
	urldate = {2021-03-10},
	author = {Muenchow, Jakub Nowosad, Jannes, Robin Lovelace}
}

@inproceedings{brenning_spatial_2012,
	title = {Spatial cross-validation and bootstrap for the assessment of prediction rules in remote sensing: {The} {R} package sperrorest},
	shorttitle = {Spatial cross-validation and bootstrap for the assessment of prediction rules in remote sensing},
	doi = {10.1109/IGARSS.2012.6352393},
	abstract = {Novel computational and statistical prediction methods such as the support vector machine are becoming increasingly popular in remote-sensing applications and need to be compared to more traditional approaches like maximum-likelihood classification. However, the accuracy assessment of such predictive models in a spatial context needs to account for the presence of spatial autocorrelation in geospatial data by using spatial cross-validation and bootstrap strategies instead of their now more widely used non-spatial equivalent. These spatial resampling-based estimation procedures were therefore implemented in a new package `sperrorest' for the open-source statistical data analysis software R. This package is introduced using the example of the detection of rock-glacier flow structures from IKONOS-derived Gabor texture features and terrain attribute data.},
	booktitle = {2012 {IEEE} {International} {Geoscience} and {Remote} {Sensing} {Symposium}},
	author = {Brenning, A.},
	month = jul,
	year = {2012},
	note = {ISSN: 2153-7003},
	keywords = {bootstrap strategies, classification accuracy, computational prediction methods, computer bootstrapping, Context, data analysis, Data analysis, Estimation, Gabor filters, geographic information systems, geophysics computing, geospatial data, IKONOS-derived Gabor texture features, land cover classification, maximum-likelihood classification, nonspatial equivalent, open-source statistical data analysis software R, pattern classification, prediction rules, prediction theory, Predictive models, R package sperrorest, remote sensing, Remote sensing, remote-sensing applications, rock glaciers, rock-glacier flow structures, Rocks, sampling methods, spatial autocorrelation, spatial bootstrap, spatial context, Spatial cross-validation, spatial crossvalidation, spatial resampling-based estimation procedures, statistical analysis, statistical prediction methods, support vector machine, support vector machines, Support vector machines, terrain attribute data},
	pages = {5372--5375}
}

@article{schratz_hyperparameter_2019,
	title = {Hyperparameter tuning and performance assessment of statistical and machine-learning algorithms using spatial data},
	volume = {406},
	issn = {0304-3800},
	url = {https://www.sciencedirect.com/science/article/pii/S0304380019302145},
	doi = {10.1016/j.ecolmodel.2019.06.002},
	abstract = {While the application of machine-learning algorithms has been highly simplified in the last years due to their well-documented integration in commonly used statistical programming languages (such as R or Python), there are several practical challenges in the field of ecological modeling related to unbiased performance estimation. One is the influence of spatial autocorrelation in both hyperparameter tuning and performance estimation. Grouped cross-validation strategies have been proposed in recent years in environmental as well as medical contexts to reduce bias in predictive performance. In this study we show the effects of spatial autocorrelation on hyperparameter tuning and performance estimation by comparing several widely used machine-learning algorithms such as boosted regression trees (BRT), k-nearest neighbor (KNN), random forest (RF) and support vector machine (SVM) with traditional parametric algorithms such as logistic regression (GLM) and semi-parametric ones like generalized additive models (GAM) in terms of predictive performance. Spatial and non-spatial cross-validation methods were used to evaluate model performances aiming to obtain bias-reduced performance estimates. A detailed analysis on the sensitivity of hyperparameter tuning when using different resampling methods (spatial/non-spatial) was performed. As a case study the spatial distribution of forest disease (Diplodia sapinea) in the Basque Country (Spain) was investigated using common environmental variables such as temperature, precipitation, soil and lithology as predictors. Random Forest (mean Brier score estimate of 0.166) outperformed all other methods with regard to predictive accuracy. Though the sensitivity to hyperparameter tuning differed between the ML algorithms, there were in most cases no substantial differences between spatial and non-spatial partitioning for hyperparameter tuning. However, spatial hyperparameter tuning maintains consistency with spatial estimation of classifier performance and should be favored over non-spatial hyperparameter optimization. High performance differences (up to 47\%) between the bias-reduced (spatial cross-validation) and overoptimistic (non-spatial cross-validation) cross-validation settings showed the high need to account for the influence of spatial autocorrelation. Overoptimistic performance estimates may lead to false actions in ecological decision making based on biased model predictions.},
	language = {en},
	urldate = {2021-03-10},
	journal = {Ecological Modelling},
	author = {Schratz, Patrick and Muenchow, Jannes and Iturritxa, Eugenia and Richter, Jakob and Brenning, Alexander},
	month = aug,
	year = {2019},
	keywords = {Hyperparameter tuning, Machine-learning, Spatial autocorrelation, Spatial cross-validation, Spatial modeling},
	pages = {109--120}
}

@article{valavi_blockcv_2019,
	title = {{blockCV}: {An} r package for generating spatially or environmentally separated folds for k-fold cross-validation of species distribution models},
	volume = {10},
	copyright = {© 2018 The Authors. Methods in Ecology and Evolution © 2018 British Ecological Society},
	issn = {2041-210X},
	shorttitle = {{blockCV}},
	url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13107},
	doi = {https://doi.org/10.1111/2041-210X.13107},
	abstract = {When applied to structured data, conventional random cross-validation techniques can lead to underestimation of prediction error, and may result in inappropriate model selection. We present the r package blockCV, a new toolbox for cross-validation of species distribution modelling. Although it has been developed with species distribution modelling in mind, it can be used for any spatial modelling. The package can generate spatially or environmentally separated folds. It includes tools to measure spatial autocorrelation ranges in candidate covariates, providing the user with insights into the spatial structure in these data. It also offers interactive graphical capabilities for creating spatial blocks and exploring data folds. Package blockCV enables modellers to more easily implement a range of evaluation approaches. It will help the modelling community learn more about the impacts of evaluation approaches on our understanding of predictive performance of species distribution models.},
	language = {en},
	number = {2},
	urldate = {2021-03-10},
	journal = {Methods in Ecology and Evolution},
	author = {Valavi, Roozbeh and Elith, Jane and Lahoz‐Monfort, José J. and Guillera‐Arroita, Gurutzeta},
	year = {2019},
	note = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13107},
	keywords = {block cross-validation, environmental blocking, model evaluation, spatial autocorrelation, spatial blocking, spatial leave-one-out, species distribution modelling, structured environment},
	pages = {225--232}
}
