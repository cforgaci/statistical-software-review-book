#  (PART) Package Development, Submission, and Review {-}


# Guide for Authors {#pkgdev}

The current chapter should be considered an extension of the corresponding
["Guide for Authors"](https://devguide.ropensci.org/guide-for-authors.html) in
rOpenSci's "Dev Guide". The principles for package development described there
also apply to statistical packages, with this chapter describing additional
processes and practices for packages intended for submission to the statistical
software peer review system.

Package authors are expected to sequentially follow the processes described
in the four sub-sections of this chapter. The first step is to determine
whether a package is likely to be considered within the scope of our review
system. The second sub-section describes our [`autotest`
tool](https://github.com/ropenscilabs/autotest), which is intended to be used
through the entire process of package development. The third sub-section
describes how to align software with our [general and category-specific
standards](#standards) for statistical software, and the final sub-section
describes the final step of badging and preparing a "*Life Cycle Statement*". 


## Scope

The first important task prior to submitting a package is to estimate whether
a package is likely to be considered within our scope for statistical software.
As described in the [Overview](#overview-scope), packages are generally
considered in scope if they fit one or more of the [categories listed
there](#overview-categories). Prior to submission, authors must choose one
or more of these categories, and document how their software aligns with the
corresponding standards given in [Chapter 6](#standards). Any software which
can be aligned with one or more sets of category-specific standards will by
definition be considered in scope.

Authors are encouraged to contact us at any point prior to, or during,
development, to ask about whether a package might be in scope, or which
categories it might fit within. Categorisation of packages may not always be
straightforward, and we particularly encourage authors who are unsure about
whether a package belongs in a particular category or not to contact us for
discussion. An initial judgement of whether or not a package belongs in
a particular category may be gained by examining the respective standards. Any
package for which a large number of standards from a particular category may be
considered applicable (regardless of whether or not they would actually be
checked) is likely to fit within that category. Once you have determined that
your package is likely to fit into one or more of our in-scope categories,
you'll need to apply our two primary development tools described in the
following two sub-sections.

## The [`autotest` package](https://github.com/ropenscilabs/autotest) {#pkgdev-autotest}

The [`autotest` package](https://github.com/ropenscilabs/autotest) is an
automated assessment tool which all packages are expected to pass in order to
be accepted for submission. The package implements a form of "mutation
testing," by examining the types of all input parameters, implementing
type-specific mutations, and examining the response of each function in
a package to all such mutations. This kind of mutation testing is a very
effective way to uncover any unexpected behaviour which authors themselves
might not necessarily pre-empt. The purpose of using
[`autotest`](https://github.com/ropenscilabs/autotest) to prepare packages is
to avoid as much as possible the common situation of reviewers discovering bugs
when they attempt to use software in ways that differ from typical uses
envisioned by authors themselves. Reviews of software prepared with the help
of [`autotest`](https://github.com/ropenscilabs/autotest) should be less
burdened by discussions of what are often minor technical details, and more
able to focus on "higher level" aspects of software quality.


Full documentation of how to use
[`autotest`](https://github.com/ropenscilabs/autotest) in package development
is provided on the [package website](https://ropenscilabs.github.io/autotest/),
and we particularly encourage any authors intending to develop packages for
submission to our peer review system to step through the [main `autotest`
vignette](https://ropenscilabs.github.io/autotest/articles/autotest.html), and
to apply [`autotest`](https://ropenscilabs.github.io/autotest/) continuously
throughout package development, to ensure that
[`autotest_package()`](https://ropenscilabs.github.io/autotest/reference/autotest_package.html)
returns clean (`NULL`) results when the package is first submitted.


## Alignment with Standards {#pkgdev-srr}

Once a package has been sufficiently developed to begin alignment with our
standards, and once all issues revealed by
[`autotest`](https://ropenscilabs.github.io/autotest/) have been addressed,
authors will need to use our second tool, the [`ssr` (**s**oftware
**r**eveiw **r**oclets) package](https://ropenscilabs.github.io/srr/) to insert
both general and category-specific standards into their code, and to begin the
process of documenting within the code itself how and where the code adheres to
the individual standards. The [`srr`
package](https://ropenscilabs.github.io/srr/) can be installed locally by
running either one of the following two lines.

```{r srr-install-dev, eval = FALSE, echo = TRUE}
remotes::install_github("ropenscilabs/srr")
pak::pkg_install("ropenscilabs/srr")
```

`srr` procedures are described in detail on the [package
website](https://ropenscilabs.github.io/srr/), and in particular in the
[main vignette](https://ropenscilabs.github.io/srr/articles/srr-stats.html).
Authors are first encouraged to obtain a local copy of the [source code for
that
vignette](https://github.com/ropenscilabs/srr/blob/main/vignettes/srr-stats.Rmd),
and to step through each line in order to understand how the procedure works.
Having done that, you may then insert standards into your own package by
running the following line from within the local directory of your package,

```{r ssr-standards, eval = FALSE, echo = TRUE}
srr_stats_roxygen (category = c ("<category-1>", "<category-2>"))
```

That will insert a new file into the `R/` directory of your package called (by
default) `srr-stats-standards.R`. All standards initially have
a [`roxygen2`](https://roxygen2.r-lib.org) tag of `@srrstatsTODO`, to indicate
that these standards are yet to be addressed. These tags are processed by the 
[`srr` roclet](https://ropenscilabs.github.io/srr/) which needs to be connected
with your package by modifying the `Roxygen` line of your `DESCRIPTION` file to
the following form:

```{r srr-DESC, eval = FALSE, echo = TRUE}
Roxygen: list (markdown = TRUE, roclets = c ("namespace", "rd", "srr::srr_stats_roclet"))
```

You do not need to add the `srr` package anywhere else in your `DESCRIPTION`
file, nor do you need to retain this line when submitting packages to CRAN (or
elsewhere). You should nevertheless retain the line at all other times, and you
can easily disable the roclet output by including `#' @srrVerbose FALSE`
somewhere within your documentation. Note that `srr` documentation lines are
used only to produce on-screen output triggered by running
[`roxygen2::roxygensise()`](https://roxygen2.r-lib.org/reference/roxygenize.html),
or the equivalent function,
[`devtools::document()`](http://devtools.r-lib.org/reference/document.html),
and do not appear in actual package documentation.

The [`srr` roclet](https://ropenscilabs.github.io/srr/) recognises and process
three tags:

1. `@srrstatsTODO` to flag standards yet to be addressed;
2. `@srrstats` to flag standards which have been addressed, and followed by
   descriptions of how your code addresses those standards; and
3. `@srrstatsNA` to flag standards which you deem not to be applicable to your
   code, followed by explanations of why you deem those standards not
   applicable.

The file generated by
[`srr_stats_roxygen()`](https://ropenscilabs.github.io/srr/reference/srr_stats_roxygen.html)
initially contains two [`roxygen2`](https://roxygen2.r-lib.org) blocks, the
first containing every standard potentially applicable to your package, tagged
with `@srrstatsTODO`, and the second with a title of `NA_standards`, to
document standards deemed not applicable. The first task after having generated
this file is to move standards to approximate locations within your package
where they are likely to be addressed. For example, standards concerning tests
should be moved somewhere within the `tests/` directory, standards concerning
documentation to the main `README.Rmd` file, or within a vignette file. The
[package
skeleton](https://ropenscilabs.github.io/srr/reference/srr_stats_pkg_skeleton.html)
includes code demonstrating how to include roclet tags within `.Rmd` files.

Moving different standards to more appropriate locations within your code will
break down an initially large single list of standards into more manageable
groups dispersed throughout your code. As each standard is addressed, it should
be moved to one or more locations in your code as near as possible to relevant
code, the tag changed from `@srrstatsTODO` to `@srrstats`, and a brief
description appended to explain how that standard is addressed. Standards
deemed not to be applicable to your package should all be grouped together
within a single [`roxygen2`](https://roxygen2.r-lib.org) block with a title of
`NA_standards`, each with a tag of `@srrstatsNA`, and a brief description of
why those standards are deemed not to be applicable.

Software to be submitted for review must contain no `@srrstatsTODO` tags --
that is, all standards must have been addressed by modifying every tag to
either `@srrstats` or `@srrstatsNA`, as described above. Two useful functions
to aid package alignment with standards are:

1. The [`srr_stats_pre_submit()`
   function](https://ropenscilabs.github.io/srr/reference/srr_stats_pre_submit.html),
   which confirms that all standards have been addressed prior to submission.
2. The [`srr_report()`
   function](https://ropenscilabs.github.io/srr/reference/srr_report.html), which generates a
   summary report with hyperlinks to locations within your code at which all
   standards are placed.

Packages may only be submitted once the [`srr_stats_pre_submit()`
function](https://ropenscilabs.github.io/srr/reference/srr_stats_pre_submit.html)
confirms that,

```{r pre-submit-success, echo = FALSE}
cli::cli_alert_success ("This package is ready to submit!")
```


## Gold, Silver, and Bronze Badges {#pkgdev-badges}

All statistical software which is recommended for acceptance by reviewers is
entitled to display an rOpenSci badge. This badge is a modified version of the
badge for the [current peer-review
system](https://devguide.ropensci.org/building.html#readme), with an additional
section on the far right indicating the version of that standards against which
the software was assessed, coloured according to the "grade" of the badge. The
three possible badges look like this:

[![](badges/stats-bronze.svg)](https://github.com/ropenscilabs/statistical-software-review-book)
**bronze** for software which is sufficiently or minimally compliant with
standards to pass review.

[![](badges/stats-silver.svg)](https://github.com/ropenscilabs/statistical-software-review-book)
**silver** for software for which complies with more than a minimal set of
applicable standards, and which extends beyond bronze in least one notable way,
as explained below.

[![](badges/stats-gold.svg)](https://github.com/ropenscilabs/statistical-software-review-book)
**gold** for software which complies with *all* standards which reviewers have
deemed potentially applicable.

The submission template requires authors to identify the category they wish to
attain from the review process. These standards are not static, and it is
always possible to elevate a badge to a higher grade subsequent to review.
Badge grades may also be downgraded for code which is not continuously aligned
with ongoing developments in standards. The following sub-sections provide
further clarification of each grade.

### Bronze [![](badges/stats-bronze.svg)](https://github.com/ropenscilabs/statistical-software-review-book) {#pkgdev-bronze}

Software which is sufficiently or minimally compliant with standards will
receive a bronze badge. One common reason for this badge is software which
authors do not intend to develop further following review. This commonly
arises for software produced from research projects which have been completed,
leaving no funding to further develop the software. Another reason might be
that software has been developed for a particular use case, with authors
unable to align it with additional standards in order to expand its general
utility. A bronze badge need not signify any weakness or inadequacy in
software, rather it will generally signify software which has been developed
for one particular use case, and which will not be subject to significant
further development.

### Silver [![](badges/stats-silver.svg)](https://github.com/ropenscilabs/statistical-software-review-book) {#pkgdev-silver}

Silver badges are granted to software which extends beyond the minimal
requirements of bronze in at least one the following four aspects:

- Compliance with a good number of standards beyond those identified as
  minimally necessary. This will require reviewers and authors to agree on
  identification of both a minimal subset of necessary standards, and a full
  set of potentially applicable standards. This aspect may be considered
  fulfilled if at least one quarter of the additional potentially applicable
  standards have been met, and should definitely be considered fulfilled if
  more than one half have been met.
- Demonstrating excellence in compliance with multiple standards from at least
  two broad sub-categories. Sub-categories are distinguished in the [Standards
  Chapter](#standards) by three numbers, so that the [*General
  Standards*](#general-standards) have five sub-categories numbered 6.1.1 to
  6.1.5. This aspect would require software to extend notably beyond the
  requirements of two or more standards in at least two sub-categories
  (regardless of whether general or category-specific standards). For example,
  software which might otherwise be assessed at bronze grade, yet which is both
  excellently documented, and has an outstanding test suite, may be considered
  to fulfil this aspect.
- Have a demonstrated *generality* of usage beyond one single envisioned use
  case. Software is frequently developed for one particular use case envisioned
  by the authors themselves. Generalising the utility of software so that it
  is readily applicable to other use cases, and satisfactorily documenting such
  generality of usage, represents another aspect which may be considered
  sufficient for software to attain a silver grade.
- Internal aspects of package structure and design. Many aspects of the
  internal structure and design of software are too variable to be effectively
  addressed by standards. Packages which are judged by reviewers to reflect
  notably excellent design choices, especially in the implementation of core
  statistical algorithms, may also be considered worthy of a silver grade.


### Gold [![](badges/stats-gold.svg)](https://github.com/ropenscilabs/statistical-software-review-book) {#pkgdev-gold}

To attain a gold badge, software must comply with all applicable standards, and
must also fulfil at least three of the four aspects described above for
silver-grade badges. Both the applicability of standards, and fulfilment of
these three aspects, will ultimately determined by reviewers. Moreover,
compliance with all grades is assessed against current standards, meaning that
a gold badge must be actively maintained as standards themselves are revised
and updated.


### Software Life Cycle Statement {#pkgdev-lifecycle}

Intentions to achieve a specific category of badge are conveyed via a "*Life
Cycle Statement*", which must be appended to a repository's [`CONTRIBUTING.md`
file](https://devguide.ropensci.org/collaboration.html#contributing-guide)
prior to submission. This statement should be in a section entitled "Life Cycle
Statement", with contents copied from the following lines, reducing the list of
four items under the first point down to the single most appropriate statement,
and replacing all other words and phrases within angled brackets.

```
1. Following review, the \<package name\> package will

    - \<Be in a stable state of development, with minimal subsequent development
      envisioned\>
    - \<Be in a stable state of development, with active subsequent development
      primarily in response to user feedback.\>
    - \<Be in a stable state of development, with some degree of active
      subsequent development as envisioned by the primary authors.\>
    - \<Be in an initially stable state of development, with a great deal of
      active subsequent development envisioned.\>

2. We, the authors of \<package name\>, hope to attain a \<standard, silver,
  gold\> badge at the end of review.
```

Once a review has been completed, this *Life Cycle Statement* can be edited by
removing all references to the review process, and changing all tense to
present ("The package is in a stable state of development ...") Additional
information on envisioned software development can be added at any stage, as in
[this
example](https://github.com/ecohealthalliance/fasterize/blob/master/CONTRIBUTING.md).
